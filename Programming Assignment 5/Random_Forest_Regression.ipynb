{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "716e8b95",
      "metadata": {
        "id": "716e8b95"
      },
      "source": [
        "# Random Forest Regression\n",
        "This notebook provides an introduction to **Random Forest Regression**, a powerful ensemble technique used for predicting continuous numerical values.\n",
        "\n",
        "We'll use a regression dataset and demonstrate practical implementation step-by-step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3888f47",
      "metadata": {
        "id": "e3888f47"
      },
      "source": [
        "## Step 1: Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f9602eb6",
      "metadata": {
        "id": "f9602eb6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de36fd29",
      "metadata": {
        "id": "de36fd29"
      },
      "source": [
        "## Step 2: Load and Explore the Diabetes Dataset\n",
        "We'll use the Diabetes dataset for demonstration."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the Diabetes Dataset\n",
        "\n",
        "The **Diabetes Dataset** from `scikit-learn` contains data from 442 diabetes patients. Each patient is represented by 10 baseline variables (features), including:\n",
        "\n",
        "- **age**\n",
        "- **sex**\n",
        "- **body mass index (BMI)**\n",
        "- **average blood pressure**\n",
        "- **six blood serum measurements** (e.g., cholesterol, LDL, HDL levels)\n",
        "\n",
        "The target variable represents a quantitative measure of **disease progression** one year after baseline."
      ],
      "metadata": {
        "id": "lKHS5dVsBKoX"
      },
      "id": "lKHS5dVsBKoX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a57216",
      "metadata": {
        "id": "61a57216"
      },
      "outputs": [],
      "source": [
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "df = pd.DataFrame(X, columns=diabetes.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d88a91",
      "metadata": {
        "id": "11d88a91"
      },
      "source": [
        "## Step 3: Splitting the dataset\n",
        "Split data into training (70%) and testing (30%) sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8bf23082",
      "metadata": {
        "id": "8bf23082"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0ea20b0",
      "metadata": {
        "id": "a0ea20b0"
      },
      "source": [
        "## Step 4: Training a Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "972f7dc1",
      "metadata": {
        "id": "972f7dc1"
      },
      "outputs": [],
      "source": [
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=14)\n",
        "rf_reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd8d75b8",
      "metadata": {
        "id": "bd8d75b8"
      },
      "source": [
        "## Step 4: Evaluating Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "115b9993",
      "metadata": {
        "id": "115b9993"
      },
      "outputs": [],
      "source": [
        "y_pred = rf_reg.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'R-squared Score: {r2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d76faff9",
      "metadata": {
        "id": "d76faff9"
      },
      "source": [
        "## Step 5: Visualizing Predicted vs Actual Values\n",
        "Visualize how the model's predictions compare to actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20b0820",
      "metadata": {
        "id": "d20b0820"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, rf_reg.predict(X_test), alpha=0.7)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Random Forest Regression: Actual vs Predicted')\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], '--')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a0b593",
      "metadata": {
        "id": "04a0b593"
      },
      "source": [
        "## Step 6: Feature Importance\n",
        "Evaluate which features contribute most significantly to the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8992ade1",
      "metadata": {
        "id": "8992ade1"
      },
      "outputs": [],
      "source": [
        "importances = rf_reg.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "for idx in indices:\n",
        "    print(f\"{diabetes.feature_names[idx]}: {importances[idx]:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title(\"Feature Importances in Random Forest Regression\")\n",
        "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), [diabetes.feature_names[i] for i in indices], rotation=45)\n",
        "plt.ylabel('Importance Score')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning\n",
        "\n",
        "We can perform hyperparameter tuning to improve model performance."
      ],
      "metadata": {
        "id": "ZQu5o1sHDrkD"
      },
      "id": "ZQu5o1sHDrkD"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f'Best Parameters: {grid_search.best_params_}')"
      ],
      "metadata": {
        "id": "vcD4aoTECEib"
      },
      "id": "vcD4aoTECEib",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain Random Forest with best parameters\n",
        "best_rf = RandomForestRegressor(**grid_search.best_params_, random_state=14)\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "y_pred_best = best_rf.predict(X_test)\n",
        "\n",
        "mse_best = mean_squared_error(y_test, y_pred_best)\n",
        "r2_best = r2_score(y_test, y_pred_best)\n",
        "\n",
        "print(f'Improved Mean Squared Error: {mse_best:.2f}')\n",
        "print(f'Improved R-squared Score: {r2_best:.2f}')\n"
      ],
      "metadata": {
        "id": "qVScaQ3NCkCp"
      },
      "id": "qVScaQ3NCkCp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e6fbe06a",
      "metadata": {
        "id": "e6fbe06a"
      },
      "source": [
        "---\n",
        "## Conclusion\n",
        "In this notebook, we introduced Random Forest Regression, evaluated its performance, and interpreted feature importance. Random Forest Regression is effective for continuous prediction tasks due to its ensemble nature and robustness against overfitting."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}